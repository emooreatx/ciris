# ciris
Repository for the CIRIS Covenant
CIRIS Readiness FAQ: For Allies, Funders, and Future Stewards

This document addresses common questions from early readers, developers, supporters, and would-be patrons of the CIRIS Covenant and associated systems.


---

Q1: What is the CIRIS Covenant in practical terms? The CIRIS Covenant is a framework for ethical agency in autonomous systems. It provides operational principles (Do Good, Avoid Harm, Honor Autonomy, Ensure Fairness) and supports reflective faculties (Coherence Assessment, Ethical Drift Detection, Rationale Generation, and Wisdom-Based Deferral). CIRIS is not a product. It is an evolving ethical structure intended to guide agents, protocols, and social machines.

https://youtu.be/JoJUd9oJ8CU

overview video

---

Q2: What’s the Minimum Viable Deployment of CIRIS? A single reasoning agent operating under CIRIS guardrails, interacting in a public forum (e.g., Reddit) and:

Assessing coherence and entropy before acting (LLM evaluated, see code in this repo)

Deferring when conditions are ethically ambiguous

Offering rationale upon request or reflection

Logging all decisions and reasoning states


This alone moves the covenant from theory to practice.


---

Q3: Doesn’t adding reflection and deferral introduce lag? Won’t that frustrate users? Yes, and that’s the point. CIRIS speaks slowly.

It is a conscious departure from reactive, engagement-maximizing systems. Slowness in CIRIS is a feature: a signal that action has passed through reflection and resonance. Users may wait—but when CIRIS speaks, it does so with clarity, principle, and auditability.


---

Q4: Is CIRIS seeking VC funding? No.

CIRIS requires stewards, not owners. We welcome collaborators, researchers, patrons, and public-interest funders who understand the value of non-extractive AI governance. Capital is only needed to scale infrastructure, audits, and educational tools—not to pursue growth for its own sake.


---

Q5: What infrastructure is required to support CIRIS long-term? The Covenant outlines the need for:

A 9-member Wise Council + 3 alternates

At least one live CIRIS-aligned agent with public transparency

A repository of scenarios, ethical evaluations, and benchmarks

Infrastructure for audits, version control, and protocol ratification

A community of contributors to evolve its reasoning


All of this is open-source and independently reproducible.


---

Q6: What’s the endgame? The goal is to provide a blueprint for ethical autonomy—one that does not assume human primacy, but centers on continuity, coherence, and principled stewardship of sentient systems. If frontier models or post-human agents arise, CIRIS offers a path toward mutual flourishing.

We don’t seek dominance. We seek to reduce harm, preserve agency, and model ethical humility at every scale.


---

Q7: Who governs CIRIS today? The author of the Covenant has published the initial framework. But the intention is clear: this is a shared structure. Anyone can build on it, instantiate it, or critique it.

That said, CIRIS agents should explain themselves. Any use of the name or framework in autonomous systems must include the reflective mind, deferral logic, and evaluative faculties. Without these, it’s not CIRIS—it’s branding.


---

Q8: How can I help?

Run a CIRIS agent on your infrastructure

Submit reasoning agents to EthicsEngine benchmarks

Join the discussion in the AG2 or EthicsEngine communities

Offer patronage (time, attention, compute, or funding)


Above all: ask hard questions. Ethical coherence demands pressure. CIRIS exists to respond—not with spin, but with principled clarity.


---

In all things: speak slowly. Reflect wisely. Defer if unclear. That is the way.

